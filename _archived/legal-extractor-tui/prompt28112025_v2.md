# Prompt: Expansão do Legal Text Extractor — Arquitetura de Escalonamento OCR

---

## Conceito Central: Escalonamento Progressivo

**Princípio:** "Escolha um engine, mas execute mais se necessário."

Não é validação universal (2x processamento sempre). É escalonamento sob demanda — 90% das páginas param no primeiro engine, apenas 10% problemáticas escalam.

```
Cartógrafo analisa página
         ↓
    ┌─────────────────────────────────────────────────────────┐
    │ NATIVE_CLEAN     → pdfplumber                      │ fim │
    │ RASTER_CLEAN     → Marker                          │ fim │
    │ RASTER_DIRTY     → Marker → confiança OK?          │     │
    │                         ├─ sim → fim                     │
    │                         └─ não → escala                  │
    │ RASTER_DEGRADED  → Marker + Tesseract → compara    │     │
    └─────────────────────────────────────────────────────────┘
```

### Marker faz ~80% do trabalho pesado

| Estágio Atual | Com Marker |
|---------------|------------|
| Cartógrafo    | Parcialmente substituído (Marker detecta layout) |
| Saneador      | Parcialmente substituído (Surya é robusto a ruído) |
| Extrator      | **Totalmente substituído** |
| Bibliotecário | **Permanece** — Marker não classifica peças jurídicas |

**O que sobra pra você:**
- Limpeza de artefatos específicos de sistemas judiciais (tarjas PJE/ESAJ/EPROC)
- Classificação semântica (taxonomia jurídica brasileira)
- Escalonamento para casos extremos onde Marker falha

---

## Contexto do Projeto

Sistema `legal-text-extractor` — extração de texto de documentos jurídicos brasileiros.

```
PDF → [Cartógrafo] → [Saneador] → [Extrator] → [Bibliotecário] → Output
       step_01       step_02       step_03       step_04
```

**Estado atual:**
- step_01 (Cartógrafo): Classifica páginas como NATIVE ou RASTER_NEEDED ✅
- step_02 (Saneador/ImageCleaner): Pré-processa imagens ✅
- step_03 (Extrator): pdfplumber (nativo) ou Tesseract (OCR) ✅
- step_04 (Bibliotecário): Classificação semântica ✅

---

## Arquitetura Alvo: Escalonamento

```
PDF
 │
 └─→ step_01 (Cartógrafo) [EXPANDIDO]
           │
           │  Classifica complexidade:
           │  - NATIVE_CLEAN
           │  - NATIVE_WITH_ARTIFACTS  
           │  - RASTER_CLEAN
           │  - RASTER_DIRTY
           │  - RASTER_DEGRADED
           │
           ├─→ NATIVE_* → pdfplumber [sem mudança]
           │
           └─→ RASTER_*
                     │
                     └─→ step_02 (ImageCleaner) [CONDICIONAL]
                               │
                               │  Só executa se:
                               │  - Marcas d'água detectadas
                               │  - Carimbos coloridos
                               │  - Artefatos de sistema judicial
                               │
                               └─→ Imagem (limpa ou original)
                                         │
                                         └─→ step_03 (Extrator) [ESCALONAMENTO]
                                                   │
                                                   ├─→ Marker (primary, se RAM ≥ 16GB)
                                                   │         │
                                                   │         └─→ confiança < 0.85?
                                                   │                   │
                                                   │                   └─→ escala para Tesseract
                                                   │
                                                   ├─→ Tesseract (primary, se RAM < 16GB)
                                                   │
                                                   └─→ [fallback] Tesseract sempre disponível
```

### Escalonamento em Código

```python
def extract_page(page_analysis):
    # 1. Páginas nativas: direto
    if page_analysis.type == NATIVE:
        return pdfplumber(page)
    
    # 2. Primary engine tenta
    result = primary_engine.extract(page)  # Marker ou Tesseract
    
    # 3. Se confiança suficiente: fim
    if result.confidence >= 0.85:
        return result
    
    # 4. Só escala se precisar
    if primary_engine.name == "marker":
        fallback_result = tesseract.extract(page)
        return resolve_best(result, fallback_result)
    
    # 5. Tesseract é terminal — flag para revisão se baixa confiança
    if result.confidence < 0.60:
        result.flag = NEEDS_REVIEW
    
    return result
```

### Resolução de Conflitos

```python
def resolve_best(marker_result, tesseract_result):
    """Decide qual resultado usar quando há escalonamento."""
    
    similarity = difflib.SequenceMatcher(
        None, 
        marker_result.text, 
        tesseract_result.text
    ).ratio()
    
    # Alta concordância: usa Marker (qualidade superior)
    if similarity > 0.90:
        return marker_result.with_confidence(HIGH)
    
    # Concordância média: usa Marker, mas flagga
    if similarity > 0.75:
        return marker_result.with_confidence(MEDIUM)
    
    # Divergência alta: precisa revisão
    return OCRResult(
        text=marker_result.text,  # Marker como default
        confidence=LOW,
        flag=NEEDS_REVIEW,
        alternatives=[tesseract_result]
    )
```

---

## Tarefa 1: Expandir Cartógrafo

Adicionar classificação de complexidade em `step_01_layout.py`:

```python
from enum import Enum

class PageComplexity(Enum):
    NATIVE_CLEAN = "native_clean"           # Texto digital, sem artefatos
    NATIVE_WITH_ARTIFACTS = "native_artifacts"  # Digital, mas com tarjas/selos
    RASTER_CLEAN = "raster_clean"           # Scan limpo, bom contraste
    RASTER_DIRTY = "raster_dirty"           # Scan com ruído, marcas d'água
    RASTER_DEGRADED = "raster_degraded"     # Scan muito degradado

def classify_complexity(page_analysis) -> PageComplexity:
    """Classifica complexidade da página para decisão de engine."""
    
    if page_analysis.type == "NATIVE":
        if has_judicial_artifacts(page_analysis):
            return PageComplexity.NATIVE_WITH_ARTIFACTS
        return PageComplexity.NATIVE_CLEAN
    
    # RASTER
    if page_analysis.contrast_score > 0.8 and not page_analysis.has_watermark:
        return PageComplexity.RASTER_CLEAN
    
    if page_analysis.contrast_score < 0.4 or page_analysis.noise_level > 0.6:
        return PageComplexity.RASTER_DEGRADED
    
    return PageComplexity.RASTER_DIRTY
```

**Expandir `layout.json`:**

```json
{
  "pages": [
    {
      "page_num": 1,
      "type": "NATIVE",
      "complexity": "native_clean",
      "recommended_engine": "pdfplumber",
      "needs_cleaning": false
    },
    {
      "page_num": 2,
      "type": "RASTER_NEEDED",
      "complexity": "raster_dirty",
      "recommended_engine": "marker",
      "needs_cleaning": true,
      "cleaning_reason": ["watermark_detected", "low_contrast"]
    }
  ]
}
```

---

## Tarefa 2: Estrutura de Engines

```
src/engines/
├── __init__.py
├── base.py                 # Interface OCREngine + OCRResult
├── tesseract_engine.py     # Wrapper existente
├── marker_engine.py        # Novo
├── surya_engine.py         # Novo (Surya standalone, sem Marker)
└── selector.py             # Seleção + escalonamento
```

### Interface Base (`base.py`)

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from PIL import Image
from typing import Optional, List

class ConfidenceLevel(Enum):
    HIGH = "high"       # >= 0.85
    MEDIUM = "medium"   # 0.60 - 0.85
    LOW = "low"         # < 0.60

class ResultFlag(Enum):
    NONE = "none"
    NEEDS_REVIEW = "needs_review"
    ESCALATED = "escalated"

@dataclass
class EngineRequirements:
    min_ram_gb: int
    recommended_ram_gb: int
    requires_gpu: bool
    models_size_gb: float

@dataclass
class OCRResult:
    text: str
    confidence: float
    confidence_level: ConfidenceLevel
    engine_used: str
    processing_time_seconds: float
    flag: ResultFlag = ResultFlag.NONE
    alternatives: List['OCRResult'] = field(default_factory=list)
    
    def with_confidence(self, level: ConfidenceLevel) -> 'OCRResult':
        return OCRResult(
            text=self.text,
            confidence=self.confidence,
            confidence_level=level,
            engine_used=self.engine_used,
            processing_time_seconds=self.processing_time_seconds,
            flag=self.flag,
            alternatives=self.alternatives
        )

class OCREngine(ABC):
    
    @property
    @abstractmethod
    def name(self) -> str:
        pass
    
    @property
    @abstractmethod
    def requirements(self) -> EngineRequirements:
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        pass
    
    @abstractmethod
    def extract_from_image(self, image: Image.Image) -> OCRResult:
        pass
    
    def extract_from_path(self, image_path: Path) -> OCRResult:
        image = Image.open(image_path)
        return self.extract_from_image(image)
```

### Seletor com Escalonamento (`selector.py`)

```python
import psutil
import difflib
from typing import Optional, Tuple
from .base import OCREngine, OCRResult, ConfidenceLevel, ResultFlag

def get_available_ram_gb() -> float:
    return psutil.virtual_memory().available / (1024 ** 3)

def get_total_ram_gb() -> float:
    return psutil.virtual_memory().total / (1024 ** 3)

class EngineSelector:
    """Seleção e escalonamento de engines OCR."""
    
    CONFIDENCE_THRESHOLD = 0.85
    SIMILARITY_HIGH = 0.90
    SIMILARITY_MEDIUM = 0.75
    
    def __init__(self, engines: list[OCREngine]):
        self.engines = {e.name: e for e in engines}
        self._primary = None
        self._fallback = None
        self._select_engines()
    
    def _select_engines(self):
        """Seleciona primary e fallback baseado em recursos."""
        total_ram = get_total_ram_gb()
        
        # Tesseract sempre é fallback
        self._fallback = self.engines.get("tesseract")
        
        # Primary depende de RAM
        if total_ram >= 16 and self.engines.get("marker", {}).is_available():
            self._primary = self.engines["marker"]
        elif total_ram >= 8 and self.engines.get("surya", {}).is_available():
            self._primary = self.engines["surya"]
        else:
            self._primary = self._fallback
    
    @property
    def primary(self) -> OCREngine:
        return self._primary
    
    @property
    def fallback(self) -> OCREngine:
        return self._fallback
    
    def extract_with_escalation(self, image) -> OCRResult:
        """
        Extrai com escalonamento progressivo.
        
        1. Primary engine tenta
        2. Se confiança >= threshold: retorna
        3. Se confiança < threshold E fallback disponível: escala
        4. Resolve melhor resultado
        """
        primary_result = self._primary.extract_from_image(image)
        
        # Confiança suficiente: fim
        if primary_result.confidence >= self.CONFIDENCE_THRESHOLD:
            return primary_result
        
        # Primary já é Tesseract (terminal): não há pra onde escalar
        if self._primary.name == "tesseract":
            if primary_result.confidence < 0.60:
                primary_result.flag = ResultFlag.NEEDS_REVIEW
            return primary_result
        
        # Escala para fallback
        fallback_result = self._fallback.extract_from_image(image)
        fallback_result.flag = ResultFlag.ESCALATED
        
        return self._resolve(primary_result, fallback_result)
    
    def _resolve(self, primary: OCRResult, fallback: OCRResult) -> OCRResult:
        """Resolve qual resultado usar após escalonamento."""
        
        similarity = difflib.SequenceMatcher(
            None, primary.text, fallback.text
        ).ratio()
        
        if similarity > self.SIMILARITY_HIGH:
            return primary.with_confidence(ConfidenceLevel.HIGH)
        
        if similarity > self.SIMILARITY_MEDIUM:
            result = primary.with_confidence(ConfidenceLevel.MEDIUM)
            result.alternatives = [fallback]
            return result
        
        # Divergência alta
        return OCRResult(
            text=primary.text,
            confidence=primary.confidence,
            confidence_level=ConfidenceLevel.LOW,
            engine_used=f"{primary.engine_used}+{fallback.engine_used}",
            processing_time_seconds=primary.processing_time_seconds + fallback.processing_time_seconds,
            flag=ResultFlag.NEEDS_REVIEW,
            alternatives=[fallback]
        )
```

---

## Tarefa 3: Implementar Engines

### TesseractEngine

```python
import pytesseract
from PIL import Image
import time
from .base import OCREngine, OCRResult, EngineRequirements, ConfidenceLevel

class TesseractEngine(OCREngine):
    
    def __init__(self, lang: str = "por", psm: int = 3):
        self.lang = lang
        self.psm = psm
    
    @property
    def name(self) -> str:
        return "tesseract"
    
    @property
    def requirements(self) -> EngineRequirements:
        return EngineRequirements(
            min_ram_gb=1,
            recommended_ram_gb=2,
            requires_gpu=False,
            models_size_gb=0.1
        )
    
    def is_available(self) -> bool:
        try:
            pytesseract.get_tesseract_version()
            return True
        except:
            return False
    
    def extract_from_image(self, image: Image.Image) -> OCRResult:
        start = time.time()
        
        # Extrai texto
        text = pytesseract.image_to_string(
            image, 
            lang=self.lang,
            config=f'--psm {self.psm}'
        )
        
        # Extrai dados de confiança
        data = pytesseract.image_to_data(
            image, 
            lang=self.lang, 
            output_type=pytesseract.Output.DICT
        )
        
        # Calcula confiança média (ignora -1 que são elementos não-texto)
        confidences = [c for c in data['conf'] if c > 0]
        avg_confidence = sum(confidences) / len(confidences) / 100 if confidences else 0.0
        
        elapsed = time.time() - start
        
        return OCRResult(
            text=text.strip(),
            confidence=avg_confidence,
            confidence_level=self._classify_confidence(avg_confidence),
            engine_used="tesseract",
            processing_time_seconds=elapsed
        )
    
    def _classify_confidence(self, conf: float) -> ConfidenceLevel:
        if conf >= 0.85:
            return ConfidenceLevel.HIGH
        if conf >= 0.60:
            return ConfidenceLevel.MEDIUM
        return ConfidenceLevel.LOW
```

### MarkerEngine

```python
from PIL import Image
import time
from .base import OCREngine, OCRResult, EngineRequirements, ConfidenceLevel
from .selector import get_total_ram_gb

class MarkerEngine(OCREngine):
    
    def __init__(self):
        self._model = None
    
    @property
    def name(self) -> str:
        return "marker"
    
    @property
    def requirements(self) -> EngineRequirements:
        return EngineRequirements(
            min_ram_gb=16,
            recommended_ram_gb=32,
            requires_gpu=False,
            models_size_gb=1.5
        )
    
    def is_available(self) -> bool:
        if get_total_ram_gb() < self.requirements.min_ram_gb:
            return False
        try:
            import marker
            return True
        except ImportError:
            return False
    
    def _load_model(self):
        """Lazy loading do modelo."""
        if self._model is None:
            from marker.converters.pdf import PdfConverter
            from marker.models import create_model_dict
            self._model = create_model_dict()
    
    def extract_from_image(self, image: Image.Image) -> OCRResult:
        """
        Nota: Marker é otimizado para PDFs completos.
        Para imagens únicas, usa o Surya interno.
        """
        start = time.time()
        self._load_model()
        
        from surya.ocr import run_ocr
        from surya.model.detection.model import load_model as load_det_model
        from surya.model.recognition.model import load_model as load_rec_model
        
        # Usa Surya (motor OCR do Marker) diretamente para imagens
        det_model = load_det_model()
        rec_model = load_rec_model()
        
        results = run_ocr([image], [["pt"]], det_model, rec_model)
        
        # Extrai texto e confiança
        text_blocks = []
        confidences = []
        
        for page_result in results:
            for line in page_result.text_lines:
                text_blocks.append(line.text)
                confidences.append(line.confidence)
        
        text = "\n".join(text_blocks)
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        elapsed = time.time() - start
        
        return OCRResult(
            text=text,
            confidence=avg_confidence,
            confidence_level=self._classify_confidence(avg_confidence),
            engine_used="marker",
            processing_time_seconds=elapsed
        )
    
    def _classify_confidence(self, conf: float) -> ConfidenceLevel:
        if conf >= 0.85:
            return ConfidenceLevel.HIGH
        if conf >= 0.60:
            return ConfidenceLevel.MEDIUM
        return ConfidenceLevel.LOW
```

---

## Tarefa 4: Integração com step_03

```python
# step_03_extract.py

from src.engines.selector import EngineSelector
from src.engines.tesseract_engine import TesseractEngine
from src.engines.marker_engine import MarkerEngine

class TextExtractor:
    
    def __init__(self, config: ExtractConfig = EXTRACT_CONFIG):
        self.config = config
        
        # Inicializa engines
        engines = [
            MarkerEngine(),
            TesseractEngine(lang=config.tesseract_lang)
        ]
        self.selector = EngineSelector(engines)
        
        logger.info(f"Primary engine: {self.selector.primary.name}")
        logger.info(f"Fallback engine: {self.selector.fallback.name}")
    
    def extract_page(self, page_analysis, image) -> OCRResult:
        """Extrai texto de uma página com escalonamento."""
        
        # Páginas nativas: pdfplumber direto
        if page_analysis.type == "NATIVE":
            return self._extract_native(page_analysis)
        
        # Raster: usa escalonamento
        return self.selector.extract_with_escalation(image)
```

---

## Tarefa 5: Testes

```python
# tests/test_engines.py

import pytest
from src.engines.selector import EngineSelector, get_total_ram_gb
from src.engines.tesseract_engine import TesseractEngine

class TestEscalation:
    
    def test_tesseract_always_available(self):
        engine = TesseractEngine()
        assert engine.is_available()
    
    def test_selector_has_fallback(self):
        engines = [TesseractEngine()]
        selector = EngineSelector(engines)
        assert selector.fallback is not None
        assert selector.fallback.name == "tesseract"
    
    def test_tesseract_is_fallback(self):
        """Tesseract é sempre o fallback."""
        from src.engines.marker_engine import MarkerEngine
        engines = [MarkerEngine(), TesseractEngine()]
        selector = EngineSelector(engines)
        assert selector.fallback.name == "tesseract"
    
    def test_marker_is_primary(self):
        """Com 16GB+, Marker é primary."""
        from src.engines.marker_engine import MarkerEngine
        engines = [MarkerEngine(), TesseractEngine()]
        selector = EngineSelector(engines)
        assert selector.primary.name == "marker"
        assert selector.fallback.name == "tesseract"
```

---

## Restrições

1. **Escalonamento, não validação universal** — só executa múltiplos engines quando necessário
2. **Tesseract é terminal** — sempre disponível, não escala pra lugar nenhum
3. **ImageCleaner permanece** — artefatos de sistemas judiciais (tarjas PJe/ESAJ) ainda precisam de limpeza específica
4. **Bibliotecário permanece** — Marker não faz classificação semântica jurídica
5. **Sem APIs pagas** — apenas processamento local

---

## Entregáveis

1. ☐ Cartógrafo expandido com `PageComplexity`
2. ☐ `layout.json` com campos `complexity`, `recommended_engine`, `needs_cleaning`
3. ☐ Estrutura `src/engines/` com interface base
4. ☐ `TesseractEngine` extraído
5. ☐ `MarkerEngine` implementado
6. ☐ `EngineSelector` com escalonamento
7. ☐ Integração com `step_03_extract.py`
8. ☐ Testes de escalonamento

---

## Pergunta Inicial

Liste a estrutura atual de `src/` para mapear onde o código de extração está e planejar a refatoração.
