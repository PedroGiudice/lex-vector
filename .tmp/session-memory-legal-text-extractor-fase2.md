# MemÃ³ria de SessÃ£o - Legal Text Extractor Fase 2 (Sistema Auto-MelhorÃ¡vel)

**Data:** 2025-11-18
**SessÃ£o:** Planejamento Fase 2 completa (SDK + Learning + Self-Improvement)
**Status:** Plano criado, aguardando implementaÃ§Ã£o

---

## CONTEXTO DA DISCUSSÃƒO

### Pergunta Inicial do UsuÃ¡rio

UsuÃ¡rio pediu explicaÃ§Ã£o sobre "Implementar separaÃ§Ã£o de seÃ§Ãµes (Claude SDK)" da Fase 2. Tinha dÃºvida sobre:
1. Uso do SDK vs Claude diretamente na conversa
2. Sistema de "aprendizado" contÃ­nuo
3. Quantidade de PDFs para testes (30 Ã© muito?)
4. Se sistema pode "aprender" como ML/AI

### Esclarecimentos Realizados

#### 1. SDK vs Claude Direto

**ESCLARECIDO:**
- **Agente = Claude "sandboxed" via API** (usuÃ¡rio entendeu corretamente!)
- **SDK Ã© necessÃ¡rio** para o agente funcionar AUTONOMAMENTE (sem usuÃ¡rio presente)
- **Eu (Claude na conversa)** posso fazer separaÃ§Ã£o em tempo real, mas agente precisa de SDK para funcionar sozinho

**Analogia usada:**
- Sem SDK = VocÃª Ã© chef, eu sou sous-chef (vocÃª precisa pedir cada vez)
- Com SDK = VocÃª Ã© chef, agente Ã© robÃ´ com IA (funciona sozinho, te liga quando precisa)

**Abordagem hÃ­brida recomendada:**
- **Fase 2A:** Eu (Claude) ajudo a validar e refinar (aprendizado assistido)
- **Fase 2B:** Agente usa SDK autonomamente (produÃ§Ã£o)

#### 2. Sistema de Aprendizado ContÃ­nuo

**SIM, Ã‰ POSSÃVEL!** Agente PODE ter aprendizado contÃ­nuo via:

**TÃ©cnica 1: Few-Shot Learning**
```python
# Agente adiciona exemplos de sucesso ao prompt
prompt = f"""
EXEMPLOS DE SUCESSO:
{format_examples(successful_cases)}

Agora analise ESTE documento:
{novo_texto}
"""
```

**TÃ©cnica 2: MemÃ³ria de PadrÃµes Persistente**
```python
# Agente salva padrÃµes aprendidos em JSON
learned_patterns.json â†’ atualizado apÃ³s cada teste
# PrÃ³xima execuÃ§Ã£o carrega padrÃµes anteriores
```

**TÃ©cnica 3: Auto-AtualizaÃ§Ã£o de Prompts**
```python
# Agente MELHORA SEU PRÃ“PRIO PROMPT
def _update_prompt_template(self):
    improved_prompt = self.prompt + f"""
    PADRÃ•ES APRENDIDOS (atualizado automaticamente):
    {self.learned_patterns}
    """
    save_file("prompts/current.txt", improved_prompt)
```

**Resultado:** Agente melhora SOZINHO apÃ³s cada teste! ğŸ¯

#### 3. 30 PDFs para Testes

**RESPOSTA:** Ã‰ Ã“TIMO! Quantidade ideal.

**EstratÃ©gia sugerida:**
- **Batch 1:** 10 PDFs (validaÃ§Ã£o bÃ¡sica)
- **Batch 2:** 10 PDFs (refinamento)
- **Batch 3:** 10 PDFs (casos edge)

**NÃƒO processar tudo de uma vez** - fazer em 3 fases permite:
- Aprendizado incremental
- Ajustes entre batches
- Sistema melhora a cada batch

#### 4. Documentos Anexos (Contratos, Boletos, Prints)

**DESAFIO REAL:** Autos contÃªm:
- PeÃ§as jurÃ­dicas estruturadas âœ…
- Contratos escaneados âš ï¸
- Boletos bancÃ¡rios âš ï¸
- Prints de WhatsApp âš ï¸
- Planilhas â†’ PDF âš ï¸

**SOLUÃ‡ÃƒO:** Sistema de classificaÃ§Ã£o + OCR seletivo
```python
if doc_type == DocumentType.JUDICIAL_PIECE:
    # Processamento completo
elif doc_type == DocumentType.CONTRACT:
    # OCR + extraÃ§Ã£o de clÃ¡usulas
elif doc_type == DocumentType.INVOICE:
    # OCR + dados estruturados
elif doc_type == DocumentType.SCREENSHOT:
    # OCR bÃ¡sico, baixa prioridade
elif doc_type == DocumentType.IRRELEVANT:
    # Pular, apenas registrar
```

---

## DECISÃƒO FINAL DO USUÃRIO

**"Implementar sistema COMPLETO agora (SDK + Learning + Auto-improvement)"**

**Justificativa:**
- Testar sistema REAL desde o inÃ­cio
- Few-shot learning comeÃ§a imediatamente
- Economia de tempo (uma rodada de testes)
- Ajustes conforme necessÃ¡rio durante desenvolvimento

---

## PLANO COMPLETO CRIADO

### Arquitetura (3 Camadas)

```
LAYER 1: Section Separation (Claude SDK)
  â”œâ”€ Identifica seÃ§Ãµes via prompt engineering
  â”œâ”€ Retorna JSON estruturado
  â””â”€ Confidence scoring

LAYER 2: Learning System
  â”œâ”€ Extrai padrÃµes de casos de sucesso
  â”œâ”€ Gerencia exemplos few-shot
  â””â”€ Calcula mÃ©tricas (precision/recall/F1)

LAYER 3: Self-Improvement
  â”œâ”€ Atualiza prompts automaticamente
  â”œâ”€ Versiona mudanÃ§as
  â””â”€ A/B testing de prompts
```

### Nova Estrutura de DiretÃ³rios

```
agentes/legal-text-extractor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ learning/              # NOVO
â”‚   â”‚   â”œâ”€â”€ pattern_learner.py
â”‚   â”‚   â”œâ”€â”€ few_shot_manager.py
â”‚   â”‚   â”œâ”€â”€ metrics_tracker.py
â”‚   â”‚   â””â”€â”€ self_improver.py
â”‚   â”œâ”€â”€ memory/                # NOVO
â”‚   â”‚   â”œâ”€â”€ storage.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ prompts/               # NOVO
â”‚   â”‚   â”œâ”€â”€ base_prompts.py
â”‚   â”‚   â”œâ”€â”€ prompt_versioning.py
â”‚   â”‚   â””â”€â”€ prompt_registry.py
â”‚   â””â”€â”€ analyzers/
â”‚       â””â”€â”€ section_analyzer.py  # ATUALIZAR (adicionar SDK)
â”‚
â”œâ”€â”€ data/                      # NOVO (nÃ£o versionado)
â”‚   â”œâ”€â”€ learning/
â”‚   â”‚   â”œâ”€â”€ learned_patterns.json
â”‚   â”‚   â”œâ”€â”€ few_shot_examples.json
â”‚   â”‚   â”œâ”€â”€ metrics_history.json
â”‚   â”‚   â””â”€â”€ ground_truth/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ prompt_v1.yaml
â”‚   â”‚   â””â”€â”€ changelog.md
â”‚   â””â”€â”€ checkpoints/
â”‚
â”œâ”€â”€ scripts/                   # NOVO
â”‚   â”œâ”€â”€ batch_test.py
â”‚   â”œâ”€â”€ validate_results.py
â”‚   â””â”€â”€ export_report.py
â”‚
â””â”€â”€ test-documents/
    â”œâ”€â”€ batch_001/  (10 PDFs)
    â”œâ”€â”€ batch_002/  (10 PDFs)
    â””â”€â”€ batch_003/  (10 PDFs)
```

### 4 Milestones

#### **Milestone 1: SDK Integration (6-8h)**
**Tarefas:**
1. Setup API client com rate limiting (30min)
2. Criar prompt base para separaÃ§Ã£o (1h)
3. Parser JSON response (45min)
4. ExtraÃ§Ã£o de seÃ§Ãµes baseada em marcadores (1h)
5. Tratamento de edge cases (30min)

**Entrega:** SeparaÃ§Ã£o de seÃ§Ãµes funcionando com Claude API

#### **Milestone 2: Learning System (8-10h)**
**Tarefas:**
1. Criar schemas Pydantic (45min)
2. Implementar storage JSON (1h)
3. Pattern extraction logic (2h)
4. Few-shot manager (1.5h)
5. Metrics tracker (precision/recall/F1) (1.5h)

**Entrega:** Sistema que aprende com cada teste

#### **Milestone 3: Self-Improvement (6-8h)**
**Tarefas:**
1. Sistema de versionamento de prompts (1h)
2. Self-improver logic (2h)
3. A/B testing de prompts (1.5h)

**Entrega:** Agente que atualiza prÃ³prios prompts automaticamente

#### **Milestone 4: End-to-End Testing (10-12h)**
**Tarefas:**
1. Interface de validaÃ§Ã£o (2h)
2. Batch testing script (1.5h)
3. Report generation (1h)
4. Processar e validar 30 PDFs (6-7h)

**Entrega:** Sistema validado em 30 PDFs reais

### Cronograma Total

**30-38 horas** distribuÃ­das em 1-2 semanas:
- Dia 1-2: Milestone 1 (SDK)
- Dia 3-4: Milestone 2 (Learning)
- Dia 5: Milestone 3 (Self-Improvement)
- Dia 6-10: Milestone 4 (Testing com 30 PDFs)

---

## FLUXO DE APRENDIZADO DURANTE TESTES

```
PDF 1:
  â†“ Processa â†’ VocÃª valida â†’ Sistema aprende
  â†“ Extrai padrÃ£o: "SENTENÃ‡A comeÃ§a com 'Vistos, relatados...'"
  â†“ Adiciona exemplo ao few-shot
  â†“ Salva em learned_patterns.json

PDF 2:
  â†“ Carrega conhecimento de PDF 1
  â†“ Processa com prompt MELHORADO
  â†“ VocÃª valida â†’ Aprende mais
  â†“ Atualiza padrÃµes

PDF 10:
  â†“ Processa com conhecimento de 9 PDFs
  â†“ MÃ©tricas calculadas: F1 < 0.85 (baixa!)
  â†“ Sistema DECIDE: "Preciso melhorar!"
  â†“ ATUALIZA PROMPT AUTOMATICAMENTE
  â†“ prompt_v1.yaml â†’ prompt_v2.yaml
  â†“ Adiciona mais exemplos few-shot

PDF 11-30:
  â†“ Usa prompt v2 (melhorado)
  â†“ Performance MELHORA continuamente
  â†“ Sistema aprende padrÃµes de todos os 30 PDFs

RESULTADO FINAL:
  âœ… 20+ padrÃµes aprendidos
  âœ… Prompts auto-atualizados 2-3 vezes
  âœ… AcurÃ¡cia >90% em seÃ§Ãµes conhecidas
  âœ… Sistema pronto para produÃ§Ã£o
```

---

## DECISÃ•ES TÃ‰CNICAS IMPORTANTES

### 1. JSON Storage vs Database
**Escolhido:** JSON files
**Justificativa:**
- Volume baixo (<100 docs inicialmente)
- Simplicidade de debug
- Portabilidade (nÃ£o requer servidor)
- Git-friendly

### 2. Few-Shot Learning vs Fine-Tuning
**Escolhido:** Few-shot prompting
**Justificativa:**
- Custo: $0 extra (fine-tuning = $$$)
- Flexibilidade: atualizaÃ§Ã£o instantÃ¢nea
- Claude Sonnet 3.5 jÃ¡ excelente com few-shot

### 3. Interactive Validation vs Automated
**Escolhido:** Interactive (manual)
**Justificativa:**
- Fase inicial requer ground truth humano
- 30 PDFs = 3-5h validaÃ§Ã£o (aceitÃ¡vel)
- Qualidade > quantidade

### 4. Prompt Auto-Update Threshold
**Escolhido:** F1 < 0.85 OU 10+ novos exemplos
**Justificativa:**
- Balance estabilidade vs melhoria
- 0.85 = "bom mas nÃ£o Ã³timo"

### 5. Por Que SDK Ã‰ NecessÃ¡rio
**Resposta TÃ©cnica:**

O agente PRECISA do SDK para chamar Claude API autonomamente:
```python
from anthropic import Anthropic

client = Anthropic(api_key=...)
response = client.messages.create(...)
```

**Sem SDK:** Agente nÃ£o consegue "me ligar" (Claude API) para anÃ¡lise.

**Complexidade:** Apenas 5 linhas de cÃ³digo! NÃ£o Ã© complexo.

---

## ESTIMATIVA DE CUSTO

**Claude API (Sonnet 3.5):**
- Input: $3/million tokens
- Output: $15/million tokens

**Para 30 PDFs:**
- 30 Ã— 5k tokens input Ã— $0.003 = $0.45
- 30 Ã— 1k tokens output Ã— $0.015 = $0.45
- **Total: ~$0.90**

---

## RISCOS E MITIGAÃ‡Ã•ES

### Risco 1: Token Limits
**Problema:** Documentos >30k chars estouram limite
**MitigaÃ§Ã£o:** Dividir em chunks, processar separadamente, merge results

### Risco 2: Documentos Sem Estrutura Clara
**Problema:** PDFs antigos, mal formatados
**MitigaÃ§Ã£o:** Fallback para regex heuristics, confidence score baixo â†’ revisÃ£o manual

### Risco 3: Performance vs Custo
**Problema:** MÃºltiplas chamadas API = custo
**MitigaÃ§Ã£o:** Cache de resultados (hash do texto)

### Risco 4: Overfitting
**Problema:** Sistema memoriza em vez de generalizar
**MitigaÃ§Ã£o:** Limitar exemplos (max 10/tipo), rotacionar antigos

### Risco 5: Prompts Degradam
**Problema:** Auto-update piora performance
**MitigaÃ§Ã£o:** Versionamento obrigatÃ³rio, A/B testing, rollback fÃ¡cil

---

## COMPONENTES PRINCIPAIS A IMPLEMENTAR

### 1. Pattern Learner
```python
class PatternLearner:
    """Extrai padrÃµes de documentos validados"""

    def extract_patterns(self, validated_docs) -> list[Pattern]:
        # Analisa documentos validados
        # Identifica marcadores comuns
        # Retorna padrÃµes estruturais
```

### 2. Few-Shot Manager
```python
class FewShotManager:
    """Gerencia biblioteca de exemplos"""

    def add_example(self, doc, quality_score):
        # Adiciona exemplo de qualidade

    def get_examples(self, section_type, n=3):
        # Retorna N melhores exemplos

    def export_for_prompt(self, section_types):
        # Formata para injeÃ§Ã£o no prompt
```

### 3. Metrics Tracker
```python
class MetricsTracker:
    """Calcula precision, recall, F1"""

    def calculate(self, predictions, ground_truth):
        # Calcula mÃ©tricas
        # Retorna Metrics object

    def get_trend(self, metric_name, last_n_batches):
        # Retorna tendÃªncia (improving/declining/stable)
```

### 4. Self-Improver
```python
class SelfImprover:
    """Auto-melhoria de prompts"""

    def should_update_prompt(self, metrics):
        # Decide se deve atualizar
        # Retorna {should_update, reason, strategy}

    def generate_new_prompt(self, current_metrics):
        # Gera nova versÃ£o do prompt
        # Versiona automaticamente
```

### 5. Section Analyzer (ATUALIZADO)
```python
class SectionAnalyzer:
    """Analisa e separa seÃ§Ãµes (COM SDK)"""

    def __init__(self):
        self.client = Anthropic(api_key=...)

    def analyze(self, text, use_claude=True):
        # Carrega prompt atual
        # Injeta few-shot examples
        # Chama Claude API
        # Parse JSON response
        # Extrai seÃ§Ãµes
        # Retorna list[Section]
```

---

## WORKFLOW TÃPICO (APÃ“S IMPLEMENTAÃ‡ÃƒO)

### Processar Batch de PDFs

```bash
# 1. Adicionar PDFs
cp /caminho/*.pdf test-documents/batch_001/

# 2. Processar batch
python scripts/batch_test.py --batch-dir test-documents/batch_001 --batch-id batch_001

# 3. Validar cada documento
python scripts/validate_results.py doc001 data/batches/batch_001/doc001_result.json data/batches/batch_001/doc001_text.txt

# 4. Analisar batch (aprendizado automÃ¡tico)
python scripts/batch_test.py --analyze-batch batch_001

# 5. Gerar relatÃ³rio
python scripts/export_report.py

# Sistema atualiza prompt automaticamente se necessÃ¡rio!
```

---

## PRÃ“XIMO PASSO IMEDIATO

**Quando retomar, comeÃ§ar por:**

**MILESTONE 1 - TASK 1.1: Rate Limiting (30min)**

Implementar em `src/analyzers/section_analyzer.py`:
```python
class SectionAnalyzer:
    def __init__(self, max_retries=3, retry_delay=2.0):
        self.client = Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])
        self.max_retries = max_retries
        self.retry_delay = retry_delay

    def _call_claude_with_retry(self, prompt: str) -> str:
        """Chama Claude com retry logic"""
        for attempt in range(self.max_retries):
            try:
                message = self.client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=4096,
                    messages=[{"role": "user", "content": prompt}]
                )
                return message.content[0].text
            except RateLimitError:
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (2 ** attempt))
                    continue
                raise
```

---

## COMANDOS ÃšTEIS

### Setup
```bash
cd ~/claude-work/repos/Claude-Code-Projetos/agentes/legal-text-extractor
source .venv/bin/activate

# Criar estrutura
mkdir -p src/{learning,memory,prompts} data/{learning/ground_truth,prompts,checkpoints} scripts

# Instalar extras
pip install matplotlib tqdm pyyaml

# API key
export ANTHROPIC_API_KEY="sk-..."
```

### Debug
```bash
# Ver padrÃµes aprendidos
cat data/learning/learned_patterns.json | jq

# Ver mÃ©tricas
cat data/learning/metrics_history.json | jq '.[] | {batch: .batch_id, f1: .f1_score}'

# Ver changelog de prompts
cat data/prompts/changelog.md
```

---

## PERGUNTAS DO USUÃRIO (RESPONDIDAS)

1. âœ… **SDK vs Claude direto?** - SDK necessÃ¡rio para autonomia, mas abordagem hÃ­brida recomendada
2. âœ… **Sistema aprende?** - SIM! Via few-shot + memÃ³ria persistente + auto-update de prompts
3. âœ… **30 PDFs Ã© muito?** - NÃƒO! Ã‰ quantidade ideal (dividir em 3 batches de 10)
4. âœ… **Implementar tudo agora?** - SIM! Sistema completo desde o inÃ­cio

---

## STATUS ATUAL

- âœ… Fase 1 completa (extraÃ§Ã£o + limpeza)
- âœ… Plano Fase 2 criado (2300+ linhas)
- â¸ï¸ Aguardando inÃ­cio da implementaÃ§Ã£o
- ğŸ“‹ PrÃ³ximo: Milestone 1 - Task 1.1 (Rate Limiting)

---

**Data:** 2025-11-18
**Contexto salvo para:** Retomada em nova conversa
**Comando para retomar:** "Vamos continuar a implementaÃ§Ã£o do legal-text-extractor Fase 2. Leia a memÃ³ria de sessÃ£o."
