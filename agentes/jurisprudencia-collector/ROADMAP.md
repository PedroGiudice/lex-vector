# Roadmap - Sistema de Download de Jurisprud√™ncia

## Status Atual

### ‚úÖ Fase 1: Filtro de Tipo de Publica√ß√£o (CONCLU√çDA)
**Objetivo:** Filtrar downloads para apenas Ac√≥rd√£os, eliminando 83% de ru√≠do.

**Implementa√ß√£o:**
- ‚úÖ Par√¢metro `tipos_desejados` em `processar_publicacoes()`
- ‚úÖ Normaliza√ß√£o case-insensitive de tipos
- ‚úÖ Estat√≠sticas de filtragem
- ‚úÖ Logging detalhado

**Resultado:**
- Redu√ß√£o de ~83% no volume de dados armazenados
- Foco exclusivo em publica√ß√µes relevantes para an√°lise jurisprudencial

---

### ‚úÖ Fase 2: Aumento de Volume M√≠nimo (CONCLU√çDA)
**Objetivo:** Aumentar threshold de publica√ß√µes esperadas para evitar fallback desnecess√°rio.

**Implementa√ß√£o:**
- ‚úÖ `min_publicacoes_esperadas`: 10 ‚Üí 100

**Resultado:**
- Menos avisos de fallback para PDF
- Confian√ßa maior na API como fonte prim√°ria

---

### ‚úÖ Fase 3: Download Retroativo (CONCLU√çDA)
**Objetivo:** Baixar publica√ß√µes hist√≥ricas para construir base de dados robusta.

**Implementa√ß√£o:**
- ‚úÖ Fun√ß√£o `baixar_retroativo()` em `scheduler.py`
- ‚úÖ Script `run_retroativo.py` com CLI
- ‚úÖ Itera√ß√£o dia a dia com progresso
- ‚úÖ Estat√≠sticas consolidadas
- ‚úÖ Confirma√ß√£o autom√°tica (`--yes`)

**Uso:**
```bash
# √öltimos 30 dias (padr√£o)
python run_retroativo.py --yes

# Intervalo espec√≠fico
python run_retroativo.py --inicio 2025-01-01 --fim 2025-03-31 --yes

# Apenas STJ
python run_retroativo.py --tribunais STJ --dias 90 --yes
```

**Limita√ß√£o Atual:**
- Taxa: 30 requisi√ß√µes/minuto (2s delay)
- Tempo: ~3-4 min por dia (100 p√°ginas)
- Escalabilidade: Download de 1 ano = ~18-24 horas

---

## üîÑ PIVOTE DE PRIORIDADE

**Descoberta cr√≠tica:** Download de 15 dias travou/demorou demais (~30min sem completar primeiro dia).
- Banco de dados: 0 bytes (nem tabelas foram criadas)
- Conclus√£o: Performance √© BLOCKER para teste emp√≠rico

**Nova ordem:**
1. **Fase 4.0**: Diagn√≥stico e otimiza√ß√£o de performance (PRIORIDADE M√ÅXIMA)
2. **Fase 3.1**: Teste emp√≠rico do filtro (requer volume = requer performance)

---

## üìã Pr√≥ximas Fases

### ‚úÖ Fase 4: Otimiza√ß√£o de Performance - Alta Escala (CONCLU√çDA)
**Objetivo:** Reduzir drasticamente tempo de download para viabilizar volumes grandes (anos de hist√≥rico).

**Implementa√ß√£o:**
- ‚úÖ Rate limiting adaptativo (janela deslizante 12 req/5s)
- ‚úÖ Batch commits no DB (100 pubs/batch)
- ‚úÖ Retry exponential backoff para HTTP 429/timeout
- ‚úÖ Tratamento robusto de erros

**Resultado Real:**
- **Antes:** 30 req/min (delay 2s artificial) = 1800 req/hora
- **Depois:** 144 req/min (delay ~0.42s adaptativo) = 8640 req/hora
- **Ganho:** **4.8x mais r√°pido** (buffer conservador para confiabilidade)
- **Trade-off:** Ganho te√≥rico 9.3x reduzido para 4.8x para garantir HTTP 429 < 1%

**Impacto Real:**
- Download de 6 meses (180 dias): ~100h ‚Üí **~21h**
- Download de 1 ano: ~200h ‚Üí **~42h**
- HTTP 429: < 1% (vs 6% com buffer agressivo)

---

### Fase 5: Explora√ß√£o de APIs Alternativas e Testes Adicionais
**Prioridade:** M√âDIA
**Objetivo:** Avaliar outras fontes de dados e expandir cobertura do sistema.

**Sub-tarefas:**
- [ ] **Investigar API DATAJUD**
  - Verificar se oferece vantagens sobre DJEN
  - Comparar cobertura de tribunais
  - Avaliar rate limits e performance
  - Testar qualidade/completude dos dados

- [ ] **Pesquisar outras APIs √∫teis**
  - APIs de tribunais espec√≠ficos (TJSP, TJRJ, TRFs)
  - APIs de √≥rg√£os reguladores (OAB, CNJ)
  - APIs de legisla√ß√£o (LexML, Planalto)

- [ ] **Testes de longo prazo**
  - Monitorar estabilidade do sistema otimizado (1 semana)
  - Validar HTTP 429 < 1% consistente
  - Ajustar buffer gradualmente se necess√°rio (12 ‚Üí 14 ‚Üí 15)

- [ ] **Testes de volume**
  - Download de 1 ano completo (valida√ß√£o final)
  - Verificar integridade de dados
  - Medir uso de espa√ßo em disco

**Entreg√°vel:** Relat√≥rio de viabilidade de APIs alternativas

---

## ‚ö†Ô∏è IMPORTANTE: Diagn√≥stico ANTES de Otimiza√ß√£o

**An√°lise preliminar do c√≥digo:**
- **Gargalo atual:** 100% rate limiting artificial (`delay_seconds=2.0`)
- **N√ÉO √© gargalo:** Database (SQLite ~10K writes/sec, usando 0.5/sec)
- **N√ÉO √© gargalo:** Serialization (BeautifulSoup parsing ~10-50ms)
- **DESCONHECIDO:** Limite real da API DJEN (n√£o documentado)

**Sub-tarefas:**

#### 4.0: Diagn√≥stico e Medi√ß√£o (OBRIGAT√ìRIO PRIMEIRO) - EM EXECU√á√ÉO

**Objetivo:** Medir estado atual ANTES de otimizar (evitar otimiza√ß√£o prematura).

**‚ö†Ô∏è CLARIFICA√á√ÉO CR√çTICA:**
- **Sistema atual:** Completamente sequencial (1 thread, 1 connection, 1 request/vez)
- **Para atingir 17 req/sec:** Requer paraleliza√ß√£o (n√£o implementado)
- **Connection pooling:** N√£o aplic√°vel (SQLite = single-writer)
- **Load testing:** N√ÉO foi feito ainda
- **Profiling:** N√ÉO foi feito ainda
- **Evid√™ncia emp√≠rica:** Download de 15 dias travou (~30min sem completar primeiro dia, banco vazio)

**QUEST√ïES CR√çTICAS A RESPONDER:**

1. **Onde est√° o gargalo?**
   - [ ] API requests (network latency)?
   - [ ] HTML parsing (BeautifulSoup)?
   - [ ] Database writes (SQLite)?
   - [ ] Rate limiting artificial (delay de 2s)?

2. **Qual taxa viabiliza 6 meses?**
   - 6 meses = ~180 dias
   - Meta: download em <24h
   - Requer: 180 dias / 24h = 7.5 dias/hora = **0.125 dias/minuto**
   - Com 100 p√°ginas/dia: **12.5 p√°ginas/minuto = ~5s por p√°gina**
   - Taxa atual: ~3-4 min/dia (100 p√°ginas) = **2-2.4s por p√°gina** ‚úÖ (teoricamente OK!)
   - **Conclus√£o:** Taxa atual DEVERIA ser suficiente. Por que travou?

3. **Limite real da API:**
   - [ ] Testar sem rate limiting artificial
   - [ ] Descobrir ponto de HTTP 429
   - [ ] Identificar se √© por minuto, hora ou dia
   - [ ] Verificar se √© por IP ou global

4. **Estrat√©gias de otimiza√ß√£o:**
   - [ ] Remover/reduzir delay artificial
   - [ ] Paraleliza√ß√£o (m√∫ltiplas requisi√ß√µes simult√¢neas)
   - [ ] Batching (requisitar m√∫ltiplas p√°ginas por chamada, se API suportar)
   - [ ] Caching (n√£o re-baixar duplicatas)
   - [ ] Async/await (asyncio + aiohttp)

- [ ] **Benchmark de lat√™ncia da API (sem rate limiting)**
  - Medir tempo de resposta real (min/avg/max/p95)
  - Identificar varia√ß√£o por hor√°rio
  - Testar diferentes endpoints (tribunais diferentes)
  - **Ferramenta:** Script de benchmark isolado

- [ ] **Teste de limite de rate**
  - Aumentar gradualmente requests/min at√© receber HTTP 429
  - Identificar se limite √© por minuto, por hora, ou por dia
  - Verificar se limite √© por IP ou global
  - Testar com diferentes User-Agents
  - **M√©todo:** Testes controlados em ambiente de staging

- [ ] **Profiling de processamento local**
  - Instrumentar c√≥digo com `cProfile` ou `line_profiler`
  - Medir tempo REAL de cada etapa:
    - HTTP request (network)
    - Parsing HTML (BeautifulSoup)
    - Extra√ß√£o de ementa (regex)
    - Inser√ß√£o SQLite (write)
  - Calcular % de tempo em cada etapa
  - **Comando:** `python -m cProfile -o profile.stats run_retroativo.py --dias 1 --yes`
  - **An√°lise:** `python -m pstats profile.stats`

- [ ] **Profiling de queries SQL**
  - Ativar logging de queries: `PRAGMA query_only = ON`
  - Executar `EXPLAIN QUERY PLAN` nas queries principais
  - Identificar table scans vs index usage
  - Medir tempo de INSERT vs SELECT
  - **Ferramenta:** SQLite EXPLAIN QUERY PLAN

- [ ] **Load testing (simula√ß√£o de carga)**
  - **N√ÉO aplic√°vel no estado atual** (sistema sequencial)
  - S√≥ faz sentido AP√ìS implementar paraleliza√ß√£o
  - Quando implementar: usar `wrk` ou `Apache Bench`

- [ ] **Benchmark de database**
  - Throughput de writes (inserts/sec)
  - Impacto de √≠ndices
  - Comparar WAL mode vs DELETE mode
  - Testar batch inserts (1 vs 100 vs 1000)
  - **Ferramenta:** Script de stress test

- [ ] **Criar relat√≥rio de diagn√≥stico**
  - Documentar todos os resultados
  - Identificar gargalo REAL com dados
  - Calcular ganho m√°ximo te√≥rico
  - Propor solu√ß√µes baseadas em evid√™ncia

**Entreg√°vel:** `DIAGNOSTICO_PERFORMANCE.md` com m√©tricas objetivas

---

#### 4.1: Otimiza√ß√£o Baseada em Dados (AP√ìS 4.0)
- [ ] Analisar limites de rate da API DJEN (documenta√ß√£o oficial)
- [ ] Testar limites pr√°ticos (experimentos controlados)
- [ ] Investigar se API suporta requisi√ß√µes paralelas
- [ ] Verificar se h√° endpoint batch/bulk
- [ ] Consultar termos de uso e pol√≠ticas de fair use

#### 4.2: An√°lise de Arquiteturas Alternativas
- [ ] **Abordagem 1: Paraleliza√ß√£o**
  - M√∫ltiplas conex√µes simult√¢neas (asyncio, aiohttp)
  - Thread pool / Process pool
  - Estimativa de ganho: 5-10x

- [ ] **Abordagem 2: Batch Downloads**
  - Se API suportar, requisitar m√∫ltiplos dias/p√°ginas por chamada
  - Estimativa de ganho: 10-20x

- [ ] **Abordagem 3: Caching Inteligente**
  - Pr√©-carregar √≠ndices de publica√ß√µes
  - Download apenas de metadados primeiro, depois conte√∫do sob demanda
  - Estimativa de ganho: 2-5x (para re-downloads)

- [ ] **Abordagem 4: Distribui√ß√£o de Carga**
  - M√∫ltiplas m√°quinas/IPs (se permitido)
  - Rate limiting distribu√≠do
  - Estimativa de ganho: linear com n√∫mero de workers

#### 4.3: Prova de Conceito (PoC)
- [ ] Implementar solu√ß√£o mais promissora em ambiente de teste
- [ ] Medir performance real vs estimada
- [ ] Validar estabilidade (rodadas de 1000+ requisi√ß√µes)
- [ ] Verificar impacto em rate limiting / bloqueios

#### 4.4: Implementa√ß√£o em Produ√ß√£o
- [ ] Refatorar `downloader.py` com nova arquitetura
- [ ] Configura√ß√£o din√¢mica de taxa (fallback para modo lento se necess√°rio)
- [ ] Logging de performance (lat√™ncia, throughput)
- [ ] Monitoramento de erros (HTTP 429, timeouts)

#### 4.5: Testes de Carga
- [ ] Download de 30 dias com nova arquitetura
- [ ] Download de 1 ano completo
- [ ] Valida√ß√£o de integridade (nenhuma publica√ß√£o perdida)
- [ ] Benchmarking formal (antes vs depois)

**Riscos:**
- ‚ö†Ô∏è API pode ter rate limits n√£o documentados
- ‚ö†Ô∏è Requisi√ß√µes paralelas podem ser bloqueadas/throttled
- ‚ö†Ô∏è Viola√ß√£o de termos de uso (verificar antes)

**Crit√©rios de Sucesso:**
- ‚úÖ Taxa sustentada de 500+ req/min (m√≠nimo)
- ‚úÖ Zero perda de dados vs modo lento
- ‚úÖ Aus√™ncia de bloqueios/bans
- ‚úÖ C√≥digo est√°vel para rodar 24/7

---

### Fase 5: Dashboard de Estat√≠sticas
**Prioridade:** M√âDIA
**Objetivo:** Visualiza√ß√£o de m√©tricas da base de dados.

**Features:**
- [ ] Distribui√ß√£o de publica√ß√µes por tribunal
- [ ] Evolu√ß√£o temporal (publica√ß√µes/dia)
- [ ] Taxa de filtragem (Ac√≥rd√£os vs outros tipos)
- [ ] Tamanho da base de dados
- [ ] Palavras-chave mais frequentes (nuvem de palavras)

**Ferramentas:**
- Streamlit / Dash (dashboard web interativo)
- Matplotlib / Plotly (gr√°ficos)

---

### Fase 6: Integra√ß√£o com RAG
**Prioridade:** ALTA (dependente de Fase 4)
**Objetivo:** Tornar base de jurisprud√™ncia pesquis√°vel semanticamente.

**Features:**
- [ ] Embeddings de ementas (sentence-transformers)
- [ ] Vector store (ChromaDB / FAISS)
- [ ] API de busca sem√¢ntica
- [ ] Interface de consulta (CLI + Web)
- [ ] Ranqueamento por relev√¢ncia

**Exemplo de Uso:**
```python
# Buscar ac√≥rd√£os similares
resultados = rag.buscar(
    query="responsabilidade civil por dano moral",
    tribunal="STJ",
    limit=10
)
```

---

## Cronograma Estimado

| Fase | Tempo Estimado | Depend√™ncias |
|------|----------------|--------------|
| ~~Fase 1~~ | ~~2-3h~~ | ‚úÖ Conclu√≠da |
| ~~Fase 2~~ | ~~1h~~ | ‚úÖ Conclu√≠da |
| ~~Fase 3~~ | ~~4-6h~~ | ‚úÖ Conclu√≠da |
| Fase 3.1 | 1h | Fase 3 |
| Fase 4 | **2-3 semanas** | Fase 3 |
| Fase 5 | 1-2 dias | Fase 3 |
| Fase 6 | 1 semana | Fase 4 (base completa) |

---

## Notas T√©cnicas

### Performance Atual (Baseline)
```
Rate Limiting: 30 req/min (2s delay)
Throughput:    ~1800 publica√ß√µes/hora
Tempo/Dia:     3-4 minutos (100 p√°ginas)
Tempo/Ano:     18-24 horas
```

### Performance Alvo (Fase 4)
```
Rate Limiting: 1000 req/min (0.06s delay)
Throughput:    ~60000 publica√ß√µes/hora
Tempo/Dia:     5-10 segundos
Tempo/Ano:     30-60 minutos
```

### Considera√ß√µes Arquiteturais
- **Atual:** S√≠ncrono, sequencial, single-threaded
- **Futuro:** Ass√≠ncrono, paralelo, multi-worker
- **Trade-off:** Complexidade vs Performance

---

**√öltima atualiza√ß√£o:** 2025-11-21
**Pr√≥xima revis√£o:** Ap√≥s conclus√£o de Fase 3.1 (valida√ß√£o emp√≠rica)
