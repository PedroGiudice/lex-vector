"""
EST√ÅGIO 1: O CART√ìGRAFO (Layout Analysis)

Analisa a estrutura de p√°ginas do PDF usando histograma de densidade de caracteres.
Detecta tarjas laterais (PJe/e-SAJ) e classifica p√°ginas como NATIVE ou RASTER_NEEDED.

Algoritmo:
1. Para cada p√°gina, extrai char objects via pdfplumber
2. Cria histograma de densidade no eixo X (largura da p√°gina)
3. Detecta picos de densidade nos extremos (tarja lateral)
4. Define safe_bbox excluindo zonas de ru√≠do
5. Classifica tipo de p√°gina baseado em quantidade de texto extra√≠vel

Output: outputs/{doc_id}/layout.json
"""

import json
import sys
from pathlib import Path
from typing import Literal

import pdfplumber

# Adiciona o diret√≥rio raiz ao PYTHONPATH quando executado como script
if __name__ == "__main__":
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))

from src.config import (
    LAYOUT_CONFIG,
    LayoutConfig,
    PageType,
    PageComplexity,
    COMPLEXITY_ENGINE_MAP,
    RASTER_QUALITY_THRESHOLDS,
    RasterQualityThresholds,
    get_output_dir,
)


class LayoutAnalyzer:
    """
    Analisador de layout de PDFs usando histograma de densidade.

    Detecta tarjas laterais (PJe, e-SAJ) e classifica p√°ginas para
    determinar qual estrat√©gia de extra√ß√£o usar (nativa ou OCR).
    """

    def __init__(
        self,
        config: LayoutConfig = LAYOUT_CONFIG,
        quality_thresholds: RasterQualityThresholds = RASTER_QUALITY_THRESHOLDS
    ):
        """
        Inicializa o analisador.

        Args:
            config: Configura√ß√£o de layout (thresholds, bins, etc)
            quality_thresholds: Thresholds para classifica√ß√£o de qualidade raster
        """
        self.config = config
        self.quality_thresholds = quality_thresholds

    def analyze(self, pdf_path: Path) -> dict:
        """
        Analisa layout de todas as p√°ginas do PDF.

        Args:
            pdf_path: Caminho para o arquivo PDF

        Returns:
            Dict com estrutura:
            {
                "doc_id": "nome_arquivo",
                "total_pages": 10,
                "pages": [
                    {
                        "page_num": 1,
                        "type": "NATIVE",
                        "safe_bbox": [x0, y0, x1, y1],
                        "has_tarja": False,
                        "char_count": 1234
                    },
                    ...
                ]
            }

        Raises:
            FileNotFoundError: Se PDF n√£o existe
            ValueError: Se PDF est√° corrompido ou vazio
        """
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF n√£o encontrado: {pdf_path}")

        doc_id = pdf_path.stem
        pages_data = []

        with pdfplumber.open(pdf_path) as pdf:
            if len(pdf.pages) == 0:
                raise ValueError(f"PDF vazio: {pdf_path}")

            for page_num, page in enumerate(pdf.pages, start=1):
                page_data = self._analyze_page(page, page_num)
                pages_data.append(page_data)

        layout = {
            "doc_id": doc_id,
            "total_pages": len(pages_data),
            "pages": pages_data,
        }

        return layout

    def _analyze_page(self, page, page_num: int) -> dict:
        """
        Analisa uma p√°gina individual do PDF.

        Args:
            page: Objeto Page do pdfplumber
            page_num: N√∫mero da p√°gina (1-indexed)

        Returns:
            Dict com dados da p√°gina:
            {
                "page_num": 1,
                "type": "NATIVE" | "RASTER_NEEDED",
                "complexity": "native_clean" | "raster_dirty" | etc,
                "recommended_engine": "pdfplumber" | "tesseract" | "marker",
                "needs_cleaning": bool,
                "cleaning_reason": list[str] (opcional),
                "safe_bbox": [x0, y0, x1, y1],
                "has_tarja": bool,
                "tarja_x_cut": float | None,
                "char_count": int
            }
        """
        chars = page.chars
        page_width = page.width
        page_height = page.height

        # Detecta tarja lateral via histograma de densidade
        has_tarja, tarja_x_cut = self._detect_tarja(chars, page_width)

        # Define safe_bbox (√°rea √∫til excluindo tarja)
        if has_tarja and tarja_x_cut is not None:
            safe_bbox = [
                0,
                0,
                tarja_x_cut - self.config.safe_margin_px,
                page_height,
            ]
        else:
            safe_bbox = [0, 0, page_width, page_height]

        # Conta caracteres na safe_bbox
        char_count = sum(
            1
            for char in chars
            if (
                safe_bbox[0] <= char["x0"] <= safe_bbox[2]
                and safe_bbox[1] <= char["top"] <= safe_bbox[3]
            )
        )

        # Classifica tipo de p√°gina
        if char_count >= self.config.min_text_chars:
            page_type = PageType.NATIVE
        else:
            page_type = PageType.RASTER_NEEDED

        # Monta resultado base
        page_data = {
            "page_num": page_num,
            "type": page_type,
            "safe_bbox": safe_bbox,
            "has_tarja": has_tarja,
            "char_count": char_count,
        }

        if has_tarja and tarja_x_cut is not None:
            page_data["tarja_x_cut"] = tarja_x_cut

        # === NOVA FUNCIONALIDADE: Classifica√ß√£o de complexidade ===

        # Estimar qualidade para p√°ginas RASTER
        quality_metrics = None
        if page_type == PageType.RASTER_NEEDED:
            quality_metrics = self._estimate_raster_quality(
                page, safe_bbox, char_count
            )

        # Classificar complexidade
        complexity = self._classify_complexity(page_data, quality_metrics)
        page_data["complexity"] = complexity

        # Recomendar engine baseado em complexidade
        recommended_engine = COMPLEXITY_ENGINE_MAP.get(complexity, "pdfplumber")
        page_data["recommended_engine"] = recommended_engine

        # Determinar se precisa limpeza
        cleaning_reasons = []
        needs_cleaning = False

        if has_tarja:
            cleaning_reasons.append("lateral_stripe_detected")
            needs_cleaning = True

        if quality_metrics:
            if quality_metrics.get("has_watermark", False):
                cleaning_reasons.append("watermark_detected")
                needs_cleaning = True

            if quality_metrics.get("contrast_score", 1.0) < self.quality_thresholds.low_contrast_threshold:
                cleaning_reasons.append("low_contrast")
                needs_cleaning = True

            if quality_metrics.get("noise_level", 0.0) > self.quality_thresholds.high_noise_threshold:
                cleaning_reasons.append("high_noise")
                needs_cleaning = True

        page_data["needs_cleaning"] = needs_cleaning
        if cleaning_reasons:
            page_data["cleaning_reason"] = cleaning_reasons

        return page_data

    def _detect_tarja(
        self, chars: list, page_width: float
    ) -> tuple[bool, float | None]:
        """
        Detecta tarja lateral via histograma de densidade no eixo X.

        Algoritmo:
        1. Constr√≥i histograma de densidade de caracteres
        2. Calcula threshold: % de chars nos √∫ltimos X% da largura
        3. Se threshold excedido = tarja detectada
        4. Retorna posi√ß√£o x_cut para excluir tarja

        Args:
            chars: Lista de char objects do pdfplumber
            page_width: Largura total da p√°gina em pontos

        Returns:
            Tupla (has_tarja, x_cut):
            - has_tarja: True se tarja detectada
            - x_cut: Posi√ß√£o X onde cortar (None se sem tarja)
        """
        if not chars:
            return False, None

        # Constr√≥i histograma de densidade
        histogram = self._build_histogram(
            chars, page_width, self.config.histogram_bins
        )

        # Calcula zona de tarja (√∫ltimos X% da largura)
        tarja_zone_start_bin = int(
            self.config.histogram_bins * (1 - self.config.tarja_zone_percent)
        )

        # Conta chars na zona de tarja
        tarja_chars = sum(histogram[tarja_zone_start_bin:])
        total_chars = sum(histogram)

        if total_chars == 0:
            return False, None

        # Calcula densidade relativa
        tarja_density = tarja_chars / total_chars

        # Detecta tarja se densidade > threshold
        if tarja_density >= self.config.tarja_density_threshold:
            # Usa detec√ß√£o adaptativa ou percentual fixo
            if self.config.use_adaptive_cut:
                # Encontra boundary real entre texto e tarja
                x_cut = self._find_content_boundary(chars, page_width)
            else:
                # Fallback: corte percentual fixo (comportamento antigo)
                x_cut = page_width * (1 - self.config.tarja_zone_percent)
            return True, x_cut
        else:
            return False, None

    def _build_histogram(
        self, chars: list, page_width: float, bins: int
    ) -> list[int]:
        """
        Constr√≥i histograma de densidade de caracteres no eixo X.

        Divide a largura da p√°gina em N bins e conta quantos caracteres
        caem em cada bin baseado em sua posi√ß√£o X.

        Args:
            chars: Lista de char objects do pdfplumber
            page_width: Largura total da p√°gina em pontos
            bins: N√∫mero de bins do histograma

        Returns:
            Lista de tamanho `bins` com contagem de chars por bin
        """
        histogram = [0] * bins
        bin_width = page_width / bins

        for char in chars:
            # Posi√ß√£o X do caractere (centro)
            char_x = (char["x0"] + char["x1"]) / 2

            # Calcula qual bin pertence
            bin_idx = int(char_x / bin_width)

            # Garante que n√£o ultrapasse limites
            bin_idx = min(bin_idx, bins - 1)
            bin_idx = max(bin_idx, 0)

            histogram[bin_idx] += 1

        return histogram

    def _find_content_boundary(
        self, chars: list, page_width: float
    ) -> float:
        """
        Encontra onde o texto LEG√çTIMO termina (n√£o incluindo tarja).

        Usa detec√ß√£o de gaps: procura espa√ßos vazios significativos entre
        o corpo do texto e a tarja lateral.

        Algoritmo:
        1. Coleta posi√ß√µes x1 (fim) de todos os caracteres
        2. Agrupa por proximidade
        3. Encontra gap significativo na zona de tarja
        4. Retorna boundary = posi√ß√£o antes do gap

        Args:
            chars: Lista de char objects do pdfplumber
            page_width: Largura total da p√°gina em pontos

        Returns:
            Posi√ß√£o X onde o conte√∫do leg√≠timo termina
        """
        if not chars:
            return page_width

        # Coleta posi√ß√µes x1 (fim do caractere) - onde o texto realmente termina
        x_ends = sorted([c["x1"] for c in chars])

        if not x_ends:
            return page_width

        # Zona onde procurar gaps (√∫ltimos X% da p√°gina)
        gap_search_start = page_width * (1 - self.config.gap_search_zone_percent)

        # Procura gaps significativos na zona de tarja
        best_boundary = max(x_ends)  # fallback: maior x1

        for i in range(len(x_ends) - 1):
            current_x = x_ends[i]
            next_x = x_ends[i + 1]
            gap = next_x - current_x

            # Se encontramos um gap significativo na zona de busca
            if (
                gap >= self.config.content_gap_threshold
                and current_x >= gap_search_start
            ):
                # Este √© provavelmente o fim do conte√∫do leg√≠timo
                best_boundary = current_x
                break

        return best_boundary

    def _has_judicial_artifacts(self, page_data: dict) -> bool:
        """
        Detecta presen√ßa de artefatos judiciais (tarjas, carimbos, marcas d'√°gua).

        Args:
            page_data: Dict com dados da p√°gina (retorno de _analyze_page)

        Returns:
            True se possui artefatos judiciais (tarja lateral, etc)
        """
        # Por enquanto, considera apenas detec√ß√£o de tarja
        # TODO: Expandir para detectar carimbos e marcas d'√°gua via an√°lise de imagem
        return page_data.get("has_tarja", False)

    def _estimate_raster_quality(
        self, page, safe_bbox: list, char_count: int
    ) -> dict:
        """
        Estima qualidade de uma p√°gina rasterizada.

        Args:
            page: Objeto Page do pdfplumber
            safe_bbox: Bounding box seguro [x0, y0, x1, y1]
            char_count: N√∫mero de caracteres extra√≠dos

        Returns:
            Dict com m√©tricas de qualidade:
            {
                "contrast_score": float (0.0-1.0),
                "noise_level": float (0.0-1.0),
                "char_density": float,
                "has_watermark": bool
            }
        """
        # NOTA: Esta √© uma implementa√ß√£o placeholder que retorna valores default
        # Para implementa√ß√£o completa, seria necess√°rio:
        # 1. Renderizar p√°gina como imagem (via pdf2image ou similar)
        # 2. Calcular histograma de intensidade -> contrast_score
        # 3. Calcular vari√¢ncia local de pixels -> noise_level
        # 4. Detectar padr√µes repetitivos -> has_watermark

        # Por enquanto, usa heur√≠stica baseada apenas em char_count
        bbox_area = (safe_bbox[2] - safe_bbox[0]) * (safe_bbox[3] - safe_bbox[1])
        char_density = char_count / bbox_area if bbox_area > 0 else 0.0

        # Heur√≠stica simples: p√°ginas com poucos chars podem ser degradadas
        if char_density < 0.0001:  # Muito poucos chars
            return {
                "contrast_score": 0.3,  # Baixo contraste presumido
                "noise_level": 0.7,     # Alto ru√≠do presumido
                "char_density": char_density,
                "has_watermark": False  # N√£o detect√°vel sem an√°lise de imagem
            }
        else:
            return {
                "contrast_score": 0.85,  # Contraste razo√°vel presumido
                "noise_level": 0.3,      # Baixo ru√≠do presumido
                "char_density": char_density,
                "has_watermark": False
            }

    def _classify_complexity(
        self, page_data: dict, quality_metrics: dict | None = None
    ) -> str:
        """
        Classifica complexidade da p√°gina com granularidade.

        Args:
            page_data: Dict com dados da p√°gina (retorno de _analyze_page)
            quality_metrics: M√©tricas de qualidade raster (opcional)

        Returns:
            String de PageComplexity (ex: "native_clean", "raster_dirty")
        """
        page_type = page_data["type"]

        # NATIVE pages: verificar artefatos judiciais
        if page_type == PageType.NATIVE:
            if self._has_judicial_artifacts(page_data):
                return PageComplexity.NATIVE_WITH_ARTIFACTS
            return PageComplexity.NATIVE_CLEAN

        # RASTER_NEEDED pages: classificar por qualidade
        if quality_metrics is None:
            # Fallback: se n√£o h√° m√©tricas, assume RASTER_DIRTY como default
            return PageComplexity.RASTER_DIRTY

        contrast = quality_metrics.get("contrast_score", 0.5)
        noise = quality_metrics.get("noise_level", 0.5)
        has_watermark = quality_metrics.get("has_watermark", False)

        # RASTER_CLEAN: alto contraste e sem artefatos
        if (
            contrast > self.quality_thresholds.high_contrast_threshold
            and not has_watermark
        ):
            return PageComplexity.RASTER_CLEAN

        # RASTER_DEGRADED: baixo contraste ou muito ru√≠do
        if (
            contrast < self.quality_thresholds.low_contrast_threshold
            or noise > self.quality_thresholds.high_noise_threshold
        ):
            return PageComplexity.RASTER_DEGRADED

        # RASTER_DIRTY: caso intermedi√°rio (marca d'√°gua, ru√≠do moderado)
        return PageComplexity.RASTER_DIRTY

    def save(self, layout: dict, output_path: Path) -> None:
        """
        Salva layout.json no disco.

        Args:
            layout: Dict retornado por analyze()
            output_path: Caminho completo para salvar (ex: outputs/doc/layout.json)
        """
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(layout, f, indent=2, ensure_ascii=False)


# =============================================================================
# CLI (TYPER)
# =============================================================================

if __name__ == "__main__":
    import typer

    app = typer.Typer(
        help="EST√ÅGIO 1: An√°lise de layout de PDFs (O Cart√≥grafo)"
    )

    @app.command()
    def main(
        pdf_path: Path = typer.Argument(
            ..., help="Caminho para o arquivo PDF", exists=True
        ),
        output_dir: Path = typer.Option(
            None,
            "--output-dir",
            "-o",
            help="Diret√≥rio de sa√≠da (padr√£o: outputs/{doc_id})",
        ),
    ):
        """
        Analisa layout de um PDF e salva layout.json.

        Exemplos:
            python step_01_layout.py inputs/processo.pdf
            python step_01_layout.py inputs/processo.pdf -o custom_output/
        """
        # Resolve paths
        pdf_path = pdf_path.resolve()

        # Define output_dir
        if output_dir is None:
            output_dir = get_output_dir(pdf_path.stem)
        else:
            output_dir = output_dir.resolve()

        # Executa an√°lise
        typer.echo(f"üìä Analisando layout: {pdf_path.name}")

        analyzer = LayoutAnalyzer()
        layout = analyzer.analyze(pdf_path)

        # Salva resultado
        layout_path = output_dir / "layout.json"
        analyzer.save(layout, layout_path)

        # Relat√≥rio
        typer.echo(f"‚úÖ Layout salvo: {layout_path}")
        typer.echo(f"üìÑ Total de p√°ginas: {layout['total_pages']}")

        # Estat√≠sticas
        native_count = sum(
            1 for p in layout["pages"] if p["type"] == PageType.NATIVE
        )
        raster_count = sum(
            1 for p in layout["pages"] if p["type"] == PageType.RASTER_NEEDED
        )
        tarja_count = sum(1 for p in layout["pages"] if p["has_tarja"])

        typer.echo(f"  ‚Ä¢ NATIVE: {native_count} p√°ginas")
        typer.echo(f"  ‚Ä¢ RASTER_NEEDED: {raster_count} p√°ginas")
        typer.echo(f"  ‚Ä¢ Com tarja: {tarja_count} p√°ginas")

        # Estat√≠sticas de complexidade
        typer.echo("\nüìä Complexidade:")
        complexity_counts = {}
        for page in layout["pages"]:
            complexity = page.get("complexity", "unknown")
            complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1

        for complexity, count in sorted(complexity_counts.items()):
            typer.echo(f"  ‚Ä¢ {complexity}: {count} p√°ginas")

        # Estat√≠sticas de engines recomendados
        typer.echo("\nüîß Engines recomendados:")
        engine_counts = {}
        for page in layout["pages"]:
            engine = page.get("recommended_engine", "unknown")
            engine_counts[engine] = engine_counts.get(engine, 0) + 1

        for engine, count in sorted(engine_counts.items()):
            typer.echo(f"  ‚Ä¢ {engine}: {count} p√°ginas")

        # P√°ginas que precisam limpeza
        needs_cleaning_count = sum(
            1 for p in layout["pages"] if p.get("needs_cleaning", False)
        )
        typer.echo(f"\nüßπ P√°ginas que precisam limpeza: {needs_cleaning_count}")

    app()
