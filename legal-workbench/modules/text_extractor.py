# modules/text_extractor.py
"""
Text Extractor UI Module for Legal Workbench.

Provides Streamlit interface for the legal-text-extractor backend.
Supports low-memory mode for systems with <10GB RAM.
Integrates Step 04 (Bibliotec√°rio/Gemini classification).
"""

import streamlit as st
from pathlib import Path
import sys
import time
import json

# Adiciona o diret√≥rio do backend ao path (diret√≥rio tem h√≠fen, n√£o pode ser importado direto)
backend_path = Path(__file__).parent.parent / "ferramentas" / "legal-text-extractor"
sys.path.insert(0, str(backend_path))

from main import LegalTextExtractor, ExtractionResult
from src.steps.step_04_classify import GeminiBibliotecario, BibliotecarioConfig


def check_marker_availability(low_memory_mode: bool = False) -> tuple[bool, str]:
    """
    Check if Marker engine is available.

    Returns:
        (available, message) tuple
    """
    try:
        extractor = LegalTextExtractor(low_memory_mode=low_memory_mode)
        if extractor.marker_engine.is_available():
            return True, "Marker dispon√≠vel"
        else:
            ok, reason = extractor.marker_engine.check_resources()
            return False, reason
    except Exception as e:
        return False, str(e)


def render():
    """Renders the Streamlit UI for the Text Extractor module."""
    st.header("Text Extractor")
    st.caption("Extraia e limpe texto de documentos jur√≠dicos em PDF.")

    # --- Session State Initialization ---
    if "extraction_result" not in st.session_state:
        st.session_state.extraction_result = None
    if "low_memory_mode" not in st.session_state:
        st.session_state.low_memory_mode = False
    if "classification_result" not in st.session_state:
        st.session_state.classification_result = None
    if "enable_classification" not in st.session_state:
        st.session_state.enable_classification = False
    if "classification_skip_cleaning" not in st.session_state:
        st.session_state.classification_skip_cleaning = False
    if "classification_model" not in st.session_state:
        st.session_state.classification_model = "gemini-2.5-flash"

    # --- Configuration Sidebar ---
    with st.expander("‚öôÔ∏è Configura√ß√µes", expanded=False):
        st.subheader("Extra√ß√£o")
        low_memory = st.checkbox(
            "üîã Modo Baixa Mem√≥ria",
            value=st.session_state.low_memory_mode,
            help="Ignora verifica√ß√£o de RAM. Use se seu sistema tem <10GB RAM mas tem swap dispon√≠vel. "
                 "‚ö†Ô∏è Pode deixar o sistema lento para PDFs grandes."
        )
        st.session_state.low_memory_mode = low_memory

        st.divider()
        st.subheader("Classifica√ß√£o Sem√¢ntica (Step 04)")

        enable_classification = st.checkbox(
            "ü§ñ Ativar Classifica√ß√£o com Gemini",
            value=st.session_state.enable_classification,
            help="Classifica o documento em categorias jur√≠dicas usando IA (Gemini 2.5)."
        )
        st.session_state.enable_classification = enable_classification

        if enable_classification:
            col1, col2 = st.columns(2)

            with col1:
                model = st.selectbox(
                    "Modelo Gemini",
                    options=["gemini-2.5-flash", "gemini-2.5-pro"],
                    index=0 if st.session_state.classification_model == "gemini-2.5-flash" else 1,
                    help="Flash √© mais r√°pido e barato. Pro tem melhor qualidade."
                )
                st.session_state.classification_model = model

            with col2:
                skip_cleaning = st.checkbox(
                    "Pular limpeza contextual",
                    value=st.session_state.classification_skip_cleaning,
                    help="Desativa a fase de limpeza, gerando apenas classifica√ß√£o."
                )
                st.session_state.classification_skip_cleaning = skip_cleaning

            st.info(
                "‚ÑπÔ∏è A classifica√ß√£o identifica se√ß√µes como: Peti√ß√£o Inicial, Contesta√ß√£o, "
                "Senten√ßa, Ac√≥rd√£o, etc. A limpeza remove ru√≠do contextual preservando conte√∫do."
            )

    # --- System Status ---
    available, message = check_marker_availability(st.session_state.low_memory_mode)

    if available:
        st.success("‚úÖ Marker engine dispon√≠vel")
    else:
        st.error(f"‚ùå Marker indispon√≠vel: {message}")

        # Show helpful suggestions
        st.markdown("""
        **Poss√≠veis solu√ß√µes:**
        1. **Ative o modo baixa mem√≥ria** (checkbox acima) se voc√™ tem swap dispon√≠vel
        2. Feche outros programas para liberar RAM
        3. Reinicie o WSL2 com `wsl --shutdown` e tente novamente

        **Nota:** O Marker requer ~10GB RAM para processar PDFs com OCR.
        Sistemas com menos RAM podem usar o modo baixa mem√≥ria, mas o processamento ser√° mais lento.
        """)

        if not st.session_state.low_memory_mode:
            if st.button("üîã Tentar com Modo Baixa Mem√≥ria"):
                st.session_state.low_memory_mode = True
                st.rerun()

    # --- File Uploader ---
    uploaded_file = st.file_uploader(
        "Selecione um arquivo PDF",
        type="pdf",
        help="Fa√ßa o upload de um PDF para extrair o texto.",
        disabled=not available
    )

    if uploaded_file:
        st.info(f"Arquivo selecionado: **{uploaded_file.name}** ({uploaded_file.size / 1024:.1f} KB)")

        # --- Extraction Button ---
        if st.button("‚ñ∂Ô∏è Iniciar Extra√ß√£o", use_container_width=True, disabled=not available):
            st.session_state.extraction_result = None
            st.session_state.classification_result = None

            # Save the uploaded file temporarily to pass its path to the backend
            temp_dir = Path.home() / "juridico-data" / "temp"
            temp_dir.mkdir(exist_ok=True, parents=True)
            temp_path = temp_dir / uploaded_file.name

            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # --- Progress Bar and Execution ---
            total_steps = 3 if st.session_state.enable_classification else 2
            progress_bar = st.progress(0, "Inicializando...")
            status_text = st.empty()

            try:
                # Step 1: Extract text
                extractor = LegalTextExtractor(low_memory_mode=st.session_state.low_memory_mode)

                status_text.text(f"1/{total_steps} Extraindo texto (pode demorar alguns minutos)...")
                progress_bar.progress(int(33 if total_steps == 3 else 50))
                time.sleep(0.1)

                result = extractor.process_pdf(temp_path)

                status_text.text(f"2/{total_steps} Limpeza e an√°lise conclu√≠das!")
                progress_bar.progress(int(66 if total_steps == 3 else 100))
                time.sleep(0.5)

                st.session_state.extraction_result = result

                # Step 2 (optional): Classify with Gemini
                if st.session_state.enable_classification:
                    status_text.text(f"3/{total_steps} Classificando documento com Gemini...")
                    progress_bar.progress(75)
                    time.sleep(0.1)

                    # Save extracted text to temporary markdown file for classification
                    output_dir = temp_dir / "output"
                    output_dir.mkdir(exist_ok=True, parents=True)
                    final_md_path = output_dir / "final.md"
                    final_md_path.write_text(result.text, encoding="utf-8")

                    # Configure and run Bibliotecario
                    config = BibliotecarioConfig(
                        model=st.session_state.classification_model,
                        skip_cleaning=st.session_state.classification_skip_cleaning,
                    )
                    bibliotecario = GeminiBibliotecario(config=config)

                    classification_result = bibliotecario.process(final_md_path, output_dir)
                    st.session_state.classification_result = classification_result

                    progress_bar.progress(100)
                    status_text.success("Extra√ß√£o e classifica√ß√£o conclu√≠das com sucesso!")
                else:
                    status_text.success("Extra√ß√£o conclu√≠da com sucesso!")

                progress_bar.empty()

            except Exception as e:
                st.error(f"Ocorreu um erro durante o processamento: {e}")

                # Show more details for debugging
                if st.session_state.enable_classification and "Gemini" in str(e):
                    st.markdown("""
                    **Poss√≠veis causas do erro com Gemini:**
                    1. Verifique se a vari√°vel de ambiente `GOOGLE_API_KEY` est√° configurada
                    2. Verifique sua conex√£o com a internet
                    3. O modelo selecionado pode estar temporariamente indispon√≠vel
                    4. Tente desativar a classifica√ß√£o ou usar outro modelo
                    """)

                st.session_state.extraction_result = None
                st.session_state.classification_result = None
            finally:
                # Clean up temporary files
                if temp_path.exists():
                    temp_path.unlink()
                if st.session_state.enable_classification:
                    output_dir = temp_dir / "output"
                    if output_dir.exists():
                        import shutil
                        shutil.rmtree(output_dir)

    # --- Results Display ---
    if st.session_state.extraction_result:
        result = st.session_state.extraction_result
        st.markdown("---")
        st.subheader("Resultados da Extra√ß√£o")

        # --- Metrics ---
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Sistema Detectado", result.system_name, f"{result.confidence}%")
        col2.metric("Redu√ß√£o de Texto", f"{result.reduction_pct:.1f}%")
        col3.metric("Caracteres Originais", f"{result.original_length:,}")
        col4.metric("Caracteres Finais", f"{result.final_length:,}")

        # --- Engine Info ---
        col5, col6 = st.columns(2)
        col5.metric("P√°ginas Nativas", result.native_pages)
        col6.metric("P√°ginas OCR", result.ocr_pages)

        # --- Classification Results (if enabled) ---
        if st.session_state.classification_result:
            st.markdown("---")
            st.subheader("üìã Resultados da Classifica√ß√£o Sem√¢ntica")

            classification = st.session_state.classification_result

            # --- Classification Metrics ---
            col1, col2, col3 = st.columns(3)
            col1.metric("Total de Se√ß√µes", classification['classification'].total_sections)
            col2.metric("Total de P√°ginas", classification['classification'].total_pages)
            col3.metric("Modelo Usado", st.session_state.classification_model.replace("gemini-", "Gemini "))

            # --- Document Summary ---
            st.markdown("**Resumo do Documento:**")
            st.info(classification['classification'].summary)

            # --- Sections Table ---
            st.markdown("**Se√ß√µes Identificadas:**")
            sections_data = []
            for section in classification['classification'].sections:
                sections_data.append({
                    "Se√ß√£o": section.section_id,
                    "Tipo": section.type.value,
                    "T√≠tulo": section.title[:50] + "..." if len(section.title) > 50 else section.title,
                    "P√°ginas": f"{section.start_page}-{section.end_page}",
                    "Confian√ßa": f"{section.confidence:.0%}"
                })

            st.dataframe(sections_data, use_container_width=True, hide_index=True)

            # --- Cleaning Results (if not skipped) ---
            if classification['cleaning'] and classification['cleaning'].sections:
                st.markdown("**Resultados da Limpeza:**")
                col1, col2, col3 = st.columns(3)
                col1.metric("Caracteres Originais", f"{classification['cleaning'].total_chars_original:,}")
                col2.metric("Caracteres Limpos", f"{classification['cleaning'].total_chars_cleaned:,}")
                col3.metric("Redu√ß√£o", f"{classification['cleaning'].reduction_percent:.1f}%")

            # --- Download Buttons for Classification Outputs ---
            st.markdown("**Arquivos Gerados:**")
            download_cols = st.columns(3)

            # semantic_structure.json
            if 'semantic_structure.json' in classification['output_files']:
                with download_cols[0]:
                    structure_path = Path(classification['output_files']['semantic_structure.json'])
                    if structure_path.exists():
                        st.download_button(
                            label="üìÑ Estrutura JSON",
                            data=structure_path.read_text(encoding="utf-8"),
                            file_name="semantic_structure.json",
                            mime="application/json",
                            use_container_width=True
                        )

            # final_tagged.md
            if 'final_tagged.md' in classification['output_files']:
                with download_cols[1]:
                    tagged_path = Path(classification['output_files']['final_tagged.md'])
                    if tagged_path.exists():
                        st.download_button(
                            label="üìù Texto Tagueado",
                            data=tagged_path.read_text(encoding="utf-8"),
                            file_name="final_tagged.md",
                            mime="text/markdown",
                            use_container_width=True
                        )

            # final_cleaned.md
            if 'final_cleaned.md' in classification['output_files']:
                with download_cols[2]:
                    cleaned_path = Path(classification['output_files']['final_cleaned.md'])
                    if cleaned_path.exists():
                        st.download_button(
                            label="‚ú® Texto Limpo",
                            data=cleaned_path.read_text(encoding="utf-8"),
                            file_name="final_cleaned.md",
                            mime="text/markdown",
                            use_container_width=True
                        )

        # --- Extracted Text Output ---
        st.markdown("---")
        st.text_area(
            "Texto Extra√≠do",
            value=result.text,
            height=400,
            help="Texto limpo e processado. Padr√µes de assinatura e formata√ß√£o foram removidos."
        )

        # --- Download Button ---
        st.download_button(
            label="üì• Baixar texto extra√≠do",
            data=result.text,
            file_name=f"extracted_{uploaded_file.name.replace('.pdf', '.txt')}" if uploaded_file else "extracted.txt",
            mime="text/plain"
        )
